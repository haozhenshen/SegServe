myapp.totalUsers=100
myapp.numPartitions=5

io.rule-update.kafka.topic = RuleUpdate
io.user-range-update.kafka.topic = RangeUserUpdate
io.user-update.kafka.topic = UserUpdate
# Kafka Properties
spring.kafka.bootstrap-servers=localhost:63952
spring.kafka.consumer.group-id=test-group
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.auto-offset-reset=earliest
spring.kafka.consumer.enable-auto-commit=false


# Required connection configs for Kafka producer, consumer, and admin
#bootstrap.servers=pkc-n3603.us-central1.gcp.confluent.cloud:9092
#security.protocol=SASL_SSL
#sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username='CFPSOJHG2VO5W22W' password='wgvh0yZ5mesuBazxuJfsNTf4AWUfGER6Sct+8nMGUczP5FehKTnoFpLzN+CxuWBM';
#sasl.mechanism=PLAIN
## Required for correctness in Apache Kafka clients prior to 2.6
#client.dns.lookup=use_all_dns_ips
#
## Best practice for higher availability in Apache Kafka clients prior to 3.0
#session.timeout.ms=45000
#
## Best practice for Kafka producer to prevent data loss
#acks=all
#
## Required connection configs for Confluent Cloud Schema Registry
#schema.registry.url=https://psrc-dq2qz.us-central1.gcp.confluent.cloud
#basic.auth.credentials.source=USER_INFO
#basic.auth.user.info=JDGNHSS6M3WCGDPI:YVTmnD8cyz77lUFHHQ0S4zyeC0W19nvPmRJdTXhXUa1Zpn72YExsCVXUzKO47WlJ
